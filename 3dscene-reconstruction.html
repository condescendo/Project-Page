<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Reconstruction | Portfolio</title>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&family=JetBrains+Mono:wght@400;500&family=Libre+Franklin:wght@500;700;900&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="style.css">

    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-twilight.min.css" rel="stylesheet" />

    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

    <div class="container project-view">
        
        <header>
            <h1>3D<br>Reconstruction</h1>
            <div class="subtitle">Structure from Motion & Photogrammetry</div>
            
            <div class="stack-container">
                <span class="tech-tag">Python</span>
                <span class="tech-tag">OpenCV</span>
                <span class="tech-tag">Epipolar Geometry</span>
                <span class="tech-tag">NumPy</span>
                <span class="tech-tag">Point Clouds</span>
            </div>
        </header>

        <section id="executive-summary">
            <h3>// Executive Summary</h3>
            <p>This project implements a complete <strong>Structure from Motion (SfM)</strong> pipeline to reconstruct 3D scenes from uncalibrated 2D image sequences. By extracting invariant features and estimating the geometric relationship between camera views, the system mathematically triangulates 3D points in space. The result is a sparse point cloud that represents the scene structure and the camera trajectory.</p>
        </section>

        <section id="phase-1">
            <h2>Phase I: Feature Extraction & Matching</h2>
            <p><strong>Focus:</strong> SIFT Descriptors & FLANN Matching</p>
            <p>The first step is identifying unique points in disparate images. I utilized <strong>SIFT (Scale-Invariant Feature Transform)</strong> to detect keypoints that are robust to rotation and scaling.</p>

            <div class="media-wrapper">
                <div class="diagram-placeholder">
                    
                </div>
                <div class="caption">Figure 1: Feature Correspondence via SIFT</div>
            </div>

            <ul>
                <li><strong>Keypoint Detection:</strong> Identifying distinct corners and blobs in the image pyramid (Scale Space).</li>
                <li><strong>Feature Matching:</strong> Used the <strong>FLANN</strong> (Fast Library for Approximate Nearest Neighbors) matcher to find correspondences between image pairs based on descriptor vectors.</li>
                <li><strong>Ratio Test:</strong> Filtered weak matches by checking if the closest neighbor distance is significantly smaller than the second closest (Lowe's Ratio Test).</li>
            </ul>

            <span class="code-label">features.py / SIFT Extraction</span>
            <pre><code class="language-python"># Initialize SIFT detector
sift = cv2.SIFT_create()

# Detect keypoints and compute descriptors
kp1, des1 = sift.detectAndCompute(img1, None)
kp2, des2 = sift.detectAndCompute(img2, None)

# FLANN Parameters for KD-Tree indexing
index_params = dict(algorithm=1, trees=5)
search_params = dict(checks=50)
flann = cv2.FlannBasedMatcher(index_params, search_params)

matches = flann.knnMatch(des1, des2, k=2)</code></pre>
        </section>

        <section id="phase-2">
            <h2>Phase II: Epipolar Geometry</h2>
            <p><strong>Focus:</strong> Essential Matrix & RANSAC</p>
            <p>To recover depth, we must understand the geometric relationship between two camera views. I computed the <strong>Essential Matrix ($E$)</strong>, which encodes the rotation and translation between views.</p>
            
            <div class="media-wrapper">
                <div class="diagram-placeholder">
                    
                </div>
                <div class="caption">Figure 2: Epipolar Constraint & Triangulation</div>
            </div>

            <ul>
                <li><strong>RANSAC Loop:</strong> Used Random Sample Consensus to robustly estimate the Essential Matrix, rejecting outlier matches that don't satisfy the epipolar constraint ($x'^T E x = 0$).</li>
                <li><strong>Pose Recovery:</strong> Decomposed the matrix $E$ using Singular Value Decomposition (SVD) to recover the relative Camera Rotation ($R$) and Translation ($t$).</li>
            </ul>

            <span class="code-label">geometry.py / Pose Estimation</span>
            <pre><code class="language-python"># Compute Essential Matrix with RANSAC
E, mask = cv2.findEssentialMat(pts1, pts2, focal_length, principal_point, 
                               method=cv2.RANSAC, prob=0.999, threshold=1.0)

# Recover Rotation (R) and Translation (t)
_, R, t, mask = cv2.recoverPose(E, pts1, pts2, focal_length, principal_point)

# Projection Matrices
P1 = np.hstack((np.eye(3), np.zeros((3, 1))))
P2 = np.hstack((R, t))</code></pre>
        </section>

        <section id="phase-3">
            <h2>Phase III: Triangulation & Bundling</h2>
            <p><strong>Focus:</strong> Sparse Point Cloud Generation</p>
            <p>With the camera poses known, I performed <strong>Linear Triangulation</strong>. By back-projecting rays from matching pixels in two cameras, their intersection in 3D space defines a scene point.</p>

            <div class="media-wrapper">
                <div class="diagram-placeholder">
                    
                </div>
                <div class="caption">Figure 3: Reconstructed Sparse Point Cloud</div>
            </div>

            <ul>
                <li><strong>Triangulation:</strong> Solved the linear equation system $AX = 0$ (via SVD) to find the 3D coordinates ($X, Y, Z$) for every matched keypoint.</li>
                <li><strong>Reprojection Error:</strong> Validated the accuracy by projecting the 3D points back onto the 2D images and measuring the pixel distance drift.</li>
            </ul>

            <span class="code-label">reconstruction.py / Linear Triangulation</span>
            <pre><code class="language-python">def triangulate_points(P1, P2, pts1, pts2):
    # Triangulate points in Homogeneous coords (4D)
    points_4d = cv2.triangulatePoints(P1, P2, pts1.T, pts2.T)
    
    # Convert to Euclidean (3D) by dividing by w
    points_3d = points_4d[:3] / points_4d[3]
    
    return points_3d.T</code></pre>
        </section>

        <section id="phase-4">
            <h2>Phase IV: Visualization</h2>
            <p><strong>Focus:</strong> Open3D & Ply Export</p>
            <p>The final dataset is a list of 3D coordinates. To visualize the structure, I utilized <strong>Open3D</strong> to render the point cloud and export it to standard formats (.ply) for further processing (e.g., Poisson Surface Reconstruction).</p>

            <ul>
                <li><strong>Outlier Removal:</strong> Applied statistical outlier removal to clean noise from the point cloud before rendering.</li>
                <li><strong>Result:</strong> Successfully reconstructed the 3D geometry of static objects from handheld video footage.</li>
            </ul>
        </section>
        
        <footer>
            <div class="footer-content">
                <div>&copy; 2024 Object-Centric Pipeline</div>
                <div class="footer-links">
                    <a href="#">GitHub</a>
                    <a href="#">LinkedIn</a>
                    <a href="#">Email</a>
                </div>
            </div>
        </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>

</body>
</html>
