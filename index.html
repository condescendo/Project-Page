<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Object-Centric Inverse Rendering | Hybrid Pipeline</title>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />

    <style>
        :root {
            /* Professional Dark Palette */
            --bg-color: #0d1117;        
            --card-bg: #161b22;         
            --text-primary: #c9d1d9;    
            --text-secondary: #8b949e;  
            --accent: #58a6ff;          
            --border-color: #30363d;    
            --code-bg: #010409;         
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        body {
            background-color: var(--bg-color);
            color: var(--text-primary);
            font-family: 'Inter', sans-serif;
            line-height: 1.6;
            -webkit-font-smoothing: antialiased;
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }

        /* --- Layout --- */
        .container {
            max-width: 850px;
            margin: 0 auto;
            padding: 4rem 1.5rem;
            flex: 1; 
        }

        section { margin-bottom: 5rem; }

        /* --- Typography --- */
        h1 {
            font-size: 2.5rem;
            font-weight: 700;
            letter-spacing: -0.02em;
            margin-bottom: 0.5rem;
            color: #ffffff;
        }

        h2 {
            font-size: 1.5rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--border-color);
            color: var(--text-primary);
        }

        h3 {
            font-size: 1.1rem;
            font-weight: 600;
            margin-top: 2.5rem;
            margin-bottom: 0.75rem;
            color: var(--accent);
        }

        p {
            margin-bottom: 1.25rem;
            color: var(--text-secondary);
            font-size: 1.05rem;
        }
        
        strong { color: #e1e4e8; font-weight: 600; }

        /* Inline Code Styling */
        code:not([class*="language-"]) {
            font-family: 'JetBrains Mono', monospace;
            background: rgba(110, 118, 129, 0.4);
            color: #e1e4e8;
            padding: 0.2rem 0.4rem;
            border-radius: 6px;
            font-size: 0.85em;
        }

        /* --- Header --- */
        header { margin-bottom: 4rem; }
        .subtitle {
            font-size: 1.2rem;
            color: var(--text-secondary);
            font-weight: 400;
            font-family: 'JetBrains Mono', monospace;
        }

        /* --- Info Panels --- */
        .info-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 1.5rem;
            margin-top: 1.5rem;
            margin-bottom: 1.5rem;
        }

        .info-panel {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 6px;
            border: 1px solid var(--border-color);
            border-left: 3px solid var(--accent); 
        }
        
        .info-panel h4 {
            color: var(--text-primary);
            font-weight: 600;
            font-size: 1rem;
            margin-bottom: 0.75rem;
        }

        .info-panel p {
            font-size: 0.95rem;
            margin-bottom: 0;
            line-height: 1.5;
            color: var(--text-secondary);
        }

        /* --- Video Placeholders --- */
        .video-wrapper {
            margin: 2rem 0;
            border: 1px solid var(--border-color);
            border-radius: 8px;
            overflow: hidden;
            background: #000;
        }

        video {
            width: 100%;
            height: auto;
            display: block;
        }

        .video-caption {
            padding: 0.75rem;
            background: var(--card-bg);
            color: var(--text-secondary);
            font-size: 0.9rem;
            text-align: center;
            border-top: 1px solid var(--border-color);
            font-family: 'JetBrains Mono', monospace;
        }

        /* --- Code Blocks --- */
        pre[class*="language-"] {
            background: var(--code-bg) !important;
            border-radius: 8px;
            border: 1px solid var(--border-color);
            margin: 1rem 0 2rem 0;
            font-size: 0.85rem !important;
            overflow-x: auto; 
        }
        
        /* Custom Scrollbar for code blocks */
        pre[class*="language-"]::-webkit-scrollbar { height: 8px; }
        pre[class*="language-"]::-webkit-scrollbar-track { background: var(--code-bg); }
        pre[class*="language-"]::-webkit-scrollbar-thumb { background: #30363d; border-radius: 4px; }
        pre[class*="language-"]::-webkit-scrollbar-thumb:hover { background: #58a6ff; }

        .file-path {
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.8rem;
            color: var(--text-secondary);
            display: block;
            margin-top: 1.5rem;
            margin-bottom: 0.5rem;
            opacity: 0.8;
        }

        /* --- Tech Stack Tags --- */
        .stack-container {
            display: flex;
            flex-wrap: wrap;
            gap: 0.75rem;
        }
        .tech-tag {
            background-color: rgba(56, 139, 253, 0.15); 
            color: #58a6ff;
            border: 1px solid rgba(56, 139, 253, 0.4);
            padding: 0.3rem 0.8rem;
            border-radius: 50px;
            font-size: 0.85rem;
            font-family: 'JetBrains Mono', monospace;
        }

        /* --- List --- */
        ul {
            margin-left: 1.5rem;
            margin-bottom: 1.5rem;
            color: var(--text-secondary);
        }
        li { margin-bottom: 0.5rem; }

        /* --- Footer --- */
        footer {
            border-top: 1px solid var(--border-color);
            padding: 3rem 0;
            background-color: var(--card-bg);
            margin-top: auto;
        }
        
        .footer-content {
            max-width: 850px;
            margin: 0 auto;
            display: flex;
            justify-content: center;
            gap: 2.5rem;
            padding: 0 1.5rem;
        }

        .social-link {
            display: flex;
            align-items: center;
            gap: 0.6rem;
            color: #ffffff; 
            text-decoration: none;
            font-family: 'Inter', sans-serif;
            font-size: 0.9rem;
            font-weight: 500;
            transition: opacity 0.2s ease;
        }

        .social-link:hover {
            opacity: 0.8;
            color: var(--accent);
        }

        .social-link svg {
            width: 18px; 
            height: 18px;
            fill: currentColor;
        }

        /* Mobile Adjustments */
        @media (max-width: 600px) {
            h1 { font-size: 2rem; }
            .container { padding: 2rem 1.25rem; }
            .footer-content {
                flex-direction: column;
                align-items: center;
                gap: 1.5rem;
            }
        }
    </style>
</head>
<body>

    <div class="container">
        <header>
            <h1>Object-Centric Inverse Rendering</h1>
            <div class="subtitle">A Hybrid Python/CUDA Pipeline for Relighting</div>
        </header>

        <section>
            <h2>Background</h2>
            <p>To understand the architecture of this pipeline, it is important to distinguish between the underlying representation (Gaussian Splatting) and the rendering logic (Global Illumination).</p>

            <h3>1. 3D Gaussian Splatting (3DGS)</h3>
            <p>
                3DGS represents a paradigm shift from traditional mesh-based or voxel-based rendering. Instead of connecting vertices into triangles, 
                3DGS represents a scene as a collection of unstructured, explicit 3D ellipsoids (Gaussians). Each Gaussian possesses learnable attributes: 
                position, covariance (shape), opacity, and view-dependent color via Spherical Harmonics.
            </p>

            <div class="video-wrapper">
                <video controls poster="placeholder-thumb-1.jpg">
                    <source src="placeholder-video-1.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <div class="video-caption">Figure 1: Standard 3DGS View Synthesis (Baked Lighting)</div>
            </div>

            <div class="info-grid">
                <div class="info-panel">
                    <h4>The Capability</h4>
                    <p>This representation allows for high-fidelity novel view synthesis with real-time rasterization speeds, significantly outperforming NeRFs in training time and inference latency.</p>
                </div>
                <div class="info-panel">
                    <h4>The Limitation</h4>
                    <p>Standard 3DGS operates on "baked" radiance. The learned color is a composite of material properties and lighting conditions at the time of capture. Objects cannot be easily relit or moved without carrying strong lighting artifacts.</p>
                </div>
            </div>

            <h3>2. Global Illumination Gaussian Splatting (GI-GS)</h3>
            <p>
                GI-GS extends the Gaussian framework from simple view synthesis to Inverse Rendering. Rather than learning a single color value, 
                GI-GS aims to solve the rendering equation by decomposing the image into Physically Based Rendering (PBR) components. 
                Through differentiable rendering, the system factorizes the scene into:
            </p>
            <ul>
                <li><strong>Albedo:</strong> The base surface color independent of light.</li>
                <li><strong>Material:</strong> Surface properties such as Roughness and Metallic values.</li>
                <li><strong>Lighting:</strong> The incident environment map.</li>
            </ul>

            <div class="video-wrapper">
                 <video controls poster="placeholder-thumb-2.jpg">
                    <source src="placeholder-video-2.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <div class="video-caption">Figure 2: GI-GS Decomposed PBR Relighting</div>
            </div>

            <h3>3. The Challenge: Scene vs. Object</h3>
            <p>
                While GI-GS is powerful, existing implementations typically solve for the scene globally. They lack semantic awareness, often treating background noise as valid geometry ("floaters").
            </p>
            <p>
                This project bridges that gap. By injecting object-centric masking into the optimization loop, this pipeline constrains the PBR solver to the object of interest, ensuring that the extracted albedo and geometry are clean, distinct from the background, and ready for downstream compositing.
            </p>
        </section>

        <section>
            <h2>Project Overview</h2>
            <p>
                This project integrates <strong>Object-Centric 3D Reconstruction</strong> into the Global Illumination Gaussian Splatting (GI-GS) pipeline. 
                The goal is to create a robust Inverse Rendering framework capable of extracting individual objects from real-world scenes—separating 
                them from their background artifacts—to enable downstream tasks such as scene compositing and physically-based relighting.
            </p>
            <p>
                By modifying the rasterization backend to support visibility tracking and updating the frontend optimization logic to handle 
                segmentation masks, this pipeline solves for material properties (Albedo, Roughness, Metallic) only on valid object geometry, 
                eliminating background noise and "floaters."
            </p>
        </section>

        <section>
            <h2>System Architecture</h2>
            <p>
                The system is architected as a hybrid Python/C++ stack. High-level scene management, differentiable optimization, and loss 
                computation are handled in PyTorch (Python), while heavy-duty visibility computation and rendering are offloaded to custom CUDA kernels.
            </p>

            <h3>1. Python Integration & Logic Flow</h3>
            <p>
                The integration of Object-Centric logic into the PBR pipeline required substantial re-engineering of the training loop and data structures.
            </p>
            <ul>
                <li><strong>Masked Data Pipeline:</strong> Extended <code>dataset_readers</code> to ingest RGBA images or separate mask files. These are uploaded to VRAM as ground truth for object isolation.</li>
                <li><strong>Dual-Stage Optimization:</strong> Re-architected <code>train.py</code> to ensure object constraints persist across both Geometry (Shape) and PBR (Material) stages.</li>
                <li><strong>Topology Controller:</strong> Implemented a controller in <code>gaussian_model.py</code> that aggregates visibility data from CUDA and dynamically executes pruning.</li>
            </ul>

            <span class="file-path">Implementation Snapshot: Masked PBR Loss (Python)</span>
<pre><code class="language-python"># excerpt from train.py
# PBR Stage: Optimization of Material Properties

# 1. Retrieve rendered PBR maps and GT images
pred_albedo = render_pkg['albedo_map']
gt_image = viewpoint_cam.original_image.cuda()

# 2. Apply Segmentation Masks
# This ensures gradients are only backpropagated for pixels belonging to the object
if dataset.use_object_mask:
    object_mask = viewpoint_cam.object_mask.cuda()
    gt_image = gt_image * object_mask
    pred_albedo = pred_albedo * object_mask

# 3. Calculate Loss (L1 + Regularization)
pbr_loss = l1_loss(pred_albedo, gt_image)
total_loss = pbr_loss + (lambda_bg * background_loss)</code></pre>

            <h3>2. Custom CUDA Kernels (Backend)</h3>
            <p>
                To support the Python logic without computational overhead, I modified the underlying <code>diff-gaussian-rasterization</code> C++ submodule.
            </p>
            <ul>
                <li><strong>Direct Memory Access:</strong> Allocated a persistent boolean tensor, <code>seen</code>, directly on the GPU to track contributions across millions of iterations.</li>
                <li><strong>Kernel Modification:</strong> Rewrote the <code>renderCUDA</code> kernel in <code>forward.cu</code>. Instead of just accumulating color, the kernel performs an atomic check on the alpha contribution of every thread.</li>
            </ul>

            <span class="file-path">Snippet: submodules/diff-gaussian-rasterization/cuda_rasterizer/forward.cu</span>
<pre><code class="language-cpp">// Inside the forward rendering kernel
// Per-thread processing of Gaussian splats

if (alpha > 0.0f) {
    // Direct Global Memory Write
    // Flags the Gaussian as 'visible' without needing a separate ray-casting pass
    seen[collected_id[j]] = true; 
}</code></pre>

            <h3>3. Bridging Python and C++</h3>
            <p>
                The project uses <strong>Pybind11</strong> to expose the new CUDA functionality to PyTorch. The Python <code>render()</code> 
                function receives the <code>seen</code> tensor from the C++ return tuple. This tensor is passed to the <code>GaussianModel</code> 
                class in Python, which accumulates the state and decides when to trigger topological pruning (deletion of points).
            </p>
        </section>

        <section>
            <h2>Key Features & Results</h2>
            <div class="info-grid">
                <div class="info-panel">
                    <h4>Occlusion-Aware Pruning</h4>
                    <p>Successfully removes internal geometry that is hidden inside the object, resulting in hollow, clean meshes suitable for physics simulations.</p>
                </div>
                <div class="info-panel">
                    <h4>Artifact-Free Relighting</h4>
                    <p>By forcing the background alpha to zero, the inverse rendering solver produces clean Albedo maps, allowing the extracted object to be relit in new HDR environments without "ghosting."</p>
                </div>
                <div class="info-panel">
                    <h4>Memory Efficiency</h4>
                    <p>Pruning unseen points reduces the total Gaussian count, significantly lowering VRAM requirements during the memory-intensive PBR stage.</p>
                </div>
            </div>
        </section>

        <section>
            <h2>Build Environment</h2>
            <div class="stack-container">
                <span class="tech-tag">Python 3.8</span>
                <span class="tech-tag">C++14</span>
                <span class="tech-tag">CUDA C</span>
                <span class="tech-tag">PyTorch</span>
                <span class="tech-tag">Pybind11</span>
                <span class="tech-tag">OpenGL</span>
                <span class="tech-tag">NVIDIA A100</span>
            </div>
        </section>

    </div>

    <footer>
        <div class="footer-content">
            <a href="mailto:your.email@example.com" class="social-link">
                <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/></svg>
                <span>Email Me</span>
            </a>

            <a href="https://linkedin.com/in/yourprofile" class="social-link">
                <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/></svg>
                <span>LinkedIn</span>
            </a>

            <a href="https://github.com/yourusername" class="social-link">
                <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                <span>GitHub</span>
            </a>
        </div>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-c.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-cpp.min.js"></script>
</body>
</html>
