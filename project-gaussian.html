<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Object-Centric Inverse Rendering | Anushree Bajaj</title>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&family=JetBrains+Mono:wght@400;500&family=Libre+Franklin:wght@500;700;900&display=swap" rel="stylesheet">
    
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <div class="container">
        
        <nav class="project-nav">
            <a href="index.html" class="back-link">&larr; Back to Home</a>
        </nav>

        <header class="project-header">
            <h1>Object-Centric Inverse Rendering in Gaussian Splatting</h1>
            <p class="subtitle">An ongoing project under the chair of Augmented Vision @ DFKI and RPTU Kaiserslautern</p>
            
            <div class="tech-stack header-stack">
                <span>Python</span>
                <span>CUDA C++</span>
                <span>PyTorch</span>
                <span>Pybind11</span>
            </div>
        </header>

        <hr class="divider">

        <section id="objective">
            <h2 class="section-title">Core Objective</h2>
            <div class="content-block">
                <p class="lead-text">
                    This project integrates <strong>Object-Centric 3D Reconstruction</strong> into the <strong>Global Illumination Gaussian Splatting (GI-GS)</strong> pipeline. The goal is to create a robust Inverse Rendering framework capable of extracting individual objects from real-world scenes—separating them from their background artifacts—to enable downstream tasks such as <strong>scene compositing</strong> and <strong>physically-based relighting</strong>.
                </p>
                
                <h3>The Challenge</h3>
                <ul class="styled-list">
                    <li><strong>Gaussian Splatting:</strong> A method for novel view synthesis that is very fast and compact. It represents 3D scenes using Gaussians.</li>
                    <li><strong>The Limitation:</strong> Lighting is "baked in" as per Gaussian properties. Standard splats do not possess intrinsic lighting or material properties.</li>
                    <li><strong>The Solution:</strong> Inverse rendering allows for the relighting of Gaussian splatting scenes. In this pipeline, I am implementing <strong>Object Extraction</strong>, with reference to work done by Marcel Rogge for 2D Gaussian splatting.</li>
                </ul>

                <p>
                    By modifying the rasterization backend to support visibility tracking and updating the frontend optimization logic to handle segmentation masks, this pipeline solves for material properties (Albedo, Roughness, Metallic) only on valid object geometry, eliminating background noise and "floaters."
                </p>
            </div>
        </section>

        <section id="architecture">
            <h2 class="section-title">System Architecture</h2>
            <p>
                The system is architected as a hybrid Python/C++ stack. High-level scene management, differentiable optimization, and loss computation are handled in <strong>PyTorch (Python)</strong>, while heavy-duty visibility computation and rendering are offloaded to custom <strong>CUDA kernels</strong>.
            </p>

            <div class="subsection">
                <h3>1. Python Integration & Logic Flow</h3>
                <p>The integration of Object-Centric logic into the PBR pipeline required substantial re-engineering of the training loop and data structures.</p>
                <ul class="styled-list">
                    <li>
                        <strong>Masked Data Pipeline:</strong> Extended the <code>dataset_readers</code> and <code>Camera</code> classes to ingest RGBA images or separate mask files. These masks are uploaded to VRAM and act as the ground truth for object isolation.
                    </li>
                    <li>
                        <strong>Dual-Stage Optimization Logic:</strong> The GI-GS pipeline operates in two stages: Geometry (Shape) and PBR (Material). I re-architected the training loop in <code>train.py</code> to ensure object constraints persist across both:
                        <ul>
                            <li><em>Geometry Stage:</em> Applies a "Background Loss" to penalize opacity in masked-out regions.</li>
                            <li><em>PBR Stage:</em> Masks the Albedo, Roughness, and Metallic predictions before loss calculation. This prevents the optimizer from attempting to solve inverse rendering equations in empty space, which previously caused instability.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Topology Controller:</strong> Implemented a Python-side controller in <code>gaussian_model.py</code> that interfaces with the CUDA backend. It aggregates visibility data and executes <code>prune_unseen()</code>, dynamically altering the point cloud topology based on the rasterizer's feedback.
                    </li>
                </ul>

                <div class="code-label">Implementation Snapshot: Masked PBR Loss (Python)</div>
                <pre><code class="language-python"># excerpt from train.py
# PBR Stage: Optimization of Material Properties

# 1. Retrieve rendered PBR maps and GT images
pred_albedo = render_pkg['albedo_map']
gt_image = viewpoint_cam.original_image.cuda()

# 2. Apply Segmentation Masks
# This ensures gradients are only backpropagated for pixels belonging to the object
if dataset.use_object_mask:
    object_mask = viewpoint_cam.object_mask.cuda()
    gt_image = gt_image * object_mask
    pred_albedo = pred_albedo * object_mask

# 3. Calculate Loss (L1 + Regularization)
pbr_loss = l1_loss(pred_albedo, gt_image)
total_loss = pbr_loss + (lambda_bg * background_loss)</code></pre>
            </div>

            <div class="subsection">
                <h3>2. Custom CUDA Kernels (Backend)</h3>
                <p>To support the Python logic without computational overhead, I modified the underlying <code>diff-gaussian-rasterization</code> C++ submodule.</p>
                <ul class="styled-list">
                    <li><strong>Direct Memory Access:</strong> Allocated a persistent boolean tensor, <code>seen</code>, directly on the GPU. This buffer tracks which Gaussians have contributed to the image formation process across millions of iterations.</li>
                    <li><strong>Kernel Modification:</strong> Rewrote the <code>renderCUDA</code> kernel in <code>forward.cu</code>. Instead of just accumulating color, the kernel performs an atomic check on the alpha contribution of every thread. If a Gaussian is mathematically significant to a pixel (alpha > 0), it writes to the global memory buffer.</li>
                </ul>

                <div class="code-label">Snippet from cuda_rasterizer/forward.cu</div>
                <pre><code class="language-cpp">// Inside the forward rendering kernel
// Per-thread processing of Gaussian splats

if (alpha > 0.0f) {
    // Direct Global Memory Write
    // Flags the Gaussian as 'visible' without needing a separate ray-casting pass
    seen[collected_id[j]] = true; 
}</code></pre>
            </div>

            <div class="subsection">
                <h3>3. Bridging Python and C++</h3>
                <p>The project uses <code>Pybind11</code> to expose the new CUDA functionality to PyTorch.</p>
                <ul class="styled-list">
                    <li><strong>Forward Pass:</strong> The Python <code>render()</code> function receives the <code>seen</code> tensor from the C++ return tuple.</li>
                    <li><strong>State Management:</strong> This tensor is passed to the <code>GaussianModel</code> class in Python, which accumulates the state and decides when to trigger topological pruning (deletion of points).</li>
                </ul>
            </div>
        </section>

        <section id="results">
            <h2 class="section-title">Key Features & Results</h2>
            <div class="feature-grid">
                <div class="feature-card">
                    <h4>Occlusion-Aware Pruning</h4>
                    <p>Successfully removes internal geometry that is hidden inside the object, resulting in hollow, clean meshes suitable for physics simulations.</p>
                </div>
                <div class="feature-card">
                    <h4>Artifact-Free Relighting</h4>
                    <p>By forcing the background alpha to zero, the inverse rendering solver produces clean Albedo maps, allowing the extracted object to be relit in new HDR environments without "ghosting" artifacts.</p>
                </div>
                <div class="feature-card">
                    <h4>Memory Efficiency</h4>
                    <p>Pruning unseen points reduces the total Gaussian count, lowering VRAM requirements during the memory-intensive PBR stage.</p>
                </div>
            </div>
        </section>

        <hr class="divider">

        <section id="meta">
            <div class="meta-grid">
                <div class="meta-col">
                    <h3>Build Environment</h3>
                    <ul class="simple-list">
                        <li><strong>Languages:</strong> Python 3.8, C++14, CUDA C</li>
                        <li><strong>Libraries:</strong> PyTorch, CUDA Toolkit (11.6+), Pybind11</li>
                        <li><strong>Hardware:</strong> NVIDIA A100/A6000</li>
                    </ul>
                </div>
                <div class="meta-col">
                    <h3>Citations & Resources</h3>
                    <ul class="links-list">
                        <li><a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank">Gaussian Splatting Paper ↗</a></li>
                        <li><a href="https://github.com/stopaimme/GI-GS" target="_blank">GI-GS Repository ↗</a></li>
                        <li><a href="https://av.dfki.de/publications/object-centric-2d-gaussian-splatting-background-removal-and-occlusion-aware-pruning-for-compact-object-models/" target="_blank">Object Centric 2D Gaussian Splatting ↗</a></li>
                    </ul>
                </div>
            </div>
        </section>

        <footer>
            <div class="footer-content">
                <p>&copy; 2025 Anushree Bajaj.</p>
                <div class="footer-links">
                    <a href="https://github.com/condescendo">GitHub</a>
                    <a href="https://www.linkedin.com/in/anushree-bajaj2002/">LinkedIn</a>
                    <a href="mailto:anushreebajaj2002@gmail.com">Email</a>
                </div>
            </div>
        </footer>

    </div>
</body>
</html>
